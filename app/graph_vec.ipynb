{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "from llama_index.core import Response\n",
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    DatasetGenerator,\n",
    "    RelevancyEvaluator,\n",
    "    EvaluationResult,\n",
    "    CorrectnessEvaluator,\n",
    "    AnswerRelevancyEvaluator,\n",
    "    ContextRelevancyEvaluator,\n",
    "    BatchEvalRunner,\n",
    "    RetrieverEvaluator,\n",
    "    SemanticSimilarityEvaluator,\n",
    "    QueryResponseDataset,\n",
    ")\n",
    "\n",
    "from notebooks.helpers.bot.promtps import  (ANSWER_REL_EVAL_TEMPLATE,\n",
    "    question_gen_query,\n",
    "    EVALUATION_CORRECTNESS_SYSTEM_TEMPLATE,\n",
    "    FAITH_EVAL_TEMPLATE,\n",
    "    CONTEXT_REL_PROMPT, EVALUATION_CORRECTNESS_SYSTEM_TEMPLATE)\n",
    "from evaluate_pairings import prepare_evalution_qa, parse_evalutions, get_qr_pairs, evaluate_correctness, evaluate_faithfulness, default_parser\n",
    "from app.notebooks.helpers.bot.kg_generation import create_kg_triplets\n",
    "from notebooks.helpers.bot.bot import (\n",
    "    get_chat_engine,\n",
    "    get_query_engine,\n",
    "    load_llm,\n",
    "    load_embedding_model,\n",
    "    setup_index_and_storage,\n",
    "    generate_pairings_documents,\n",
    "    service,\n",
    ")\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_eval_df(query: str, response: Response, eval_result: Response) -> None:\n",
    "    eval_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Query\": query,\n",
    "            \"Response\": str(response),\n",
    "            \"Source\": (' '.join(eval_result.contexts)[:1000] + \"...\"),\n",
    "            \"Evaluation Result\": eval_result.passing,\n",
    "        },\n",
    "        index = [0]\n",
    "    )\n",
    "    eval_df = eval_df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"600px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        },\n",
    "        subset=[\"Response\", \"Source\"]\n",
    "    )\n",
    "    display(eval_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_triplets(text):\n",
    "    triplets = []\n",
    "    rows = text.split('\\n')\n",
    "    for row in rows[:-1]:\n",
    "        triplet = row.split('**')\n",
    "        triplets.append((triplet[0], triplet[1], triplet[2]))\n",
    "    return triplets\n",
    "\n",
    "kg_triplets = []\n",
    "\n",
    "KG = create_kg_triplets(sample_size=10, for_model=False)\n",
    "G = nx.DiGraph()\n",
    "for _, row in KG.iterrows():\n",
    "    triplets = parse_triplets(row['triplets'])\n",
    "    for triplet in triplets:\n",
    "        G.add_edge(triplet[0], triplet[2], label=triplet[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KG = create_kg_triplets()\n",
    "kg_pairings = KG.apply(generate_pairings_documents, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kg_pairings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kg_pairings.iloc[0].get_content(metadata_mode='llm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = load_llm('openai3.5')\n",
    "embed_model = load_embedding_model(\"openai3\")\n",
    "service_context = service(llm=llm, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context, kg_index = setup_index_and_storage(\n",
    "    service=service_context,\n",
    "    kg_pairings=None,\n",
    "    show_progress=False,\n",
    "    force=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevancy_eval = RelevancyEvaluator(service_context=service_context)\n",
    "faithfulness_eval = FaithfulnessEvaluator(\n",
    "    service_context=service_context, eval_template=FAITH_EVAL_TEMPLATE\n",
    ")\n",
    "semantic_eval = SemanticSimilarityEvaluator(service_context=service_context)\n",
    "answer_eval = AnswerRelevancyEvaluator(\n",
    "    service_context=service_context,\n",
    "    eval_template=ANSWER_REL_EVAL_TEMPLATE,\n",
    "    score_threshold=3.0,\n",
    ")\n",
    "context_eval = ContextRelevancyEvaluator(\n",
    "    service_context=service_context,\n",
    ")\n",
    "correctness_eval = CorrectnessEvaluator(\n",
    "    llm=load_llm(\"openai3.5\"),\n",
    "    parser_function=default_parser,\n",
    "    eval_template=EVALUATION_CORRECTNESS_SYSTEM_TEMPLATE,\n",
    ")\n",
    "\n",
    "runner = BatchEvalRunner(\n",
    "    {\n",
    "        \"relevancy\": relevancy_eval,\n",
    "        \"answer_relevancy\": answer_eval,\n",
    "        \"semantic\": semantic_eval,\n",
    "        \"context_relevancy\": context_eval,\n",
    "    },\n",
    "    workers=6,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "\n",
    "CHAT_MODE = \"context\"\n",
    "RETRIEVER_MODE = \"keyword\"\n",
    "RESPONSE_MODE = \"compact\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = get_query_engine(\n",
    "    kg_index,\n",
    "    chat_mode=CHAT_MODE,\n",
    "    retriver_mode=RETRIEVER_MODE,\n",
    "    response_mode=RESPONSE_MODE,\n",
    "    use_global_node_triplets=False,\n",
    "    max_keywords_per_query=10,\n",
    "    num_chunks_per_query=10,\n",
    "    similarity_top_k=4,\n",
    "    graph_store_query_depth=2,\n",
    "    include_text=True,  # Do not include text of the node into the model\n",
    ")\n",
    "\n",
    "\n",
    "queries, references = get_qr_pairs()\n",
    "# queries = queries[:10]\n",
    "responses = [query_engine.query(query) for query in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = runner.evaluate_responses(\n",
    "    responses = responses,\n",
    "    queries=queries,\n",
    "    reference=references,  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results[\"faithfulness\"] = evaluate_faithfulness(\n",
    "    faithfulness_eval=faithfulness_eval,\n",
    "    queries = queries,\n",
    "    references = references,\n",
    "    responses = responses,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results[\"correctnes\"] = evaluate_correctness(\n",
    "    correctness_eval,\n",
    "    queries,\n",
    "    references,\n",
    "    responses = responses,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_evalutions(\n",
    "    eval_results=eval_results,\n",
    "    model=\"gpt-3.5\",\n",
    "    embedding_model=\"gpt-3.5\",\n",
    "    chat_mode=CHAT_MODE,\n",
    "    retriever_mode=RETRIEVER_MODE,\n",
    "    response_mode=RESPONSE_MODE,\n",
    "    queries=queries,\n",
    "    responses=references,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = FaithfulnessEvaluator(service_context=service_context)\n",
    "\n",
    "chat_engine = get_chat_engine(\n",
    "    kg_index,\n",
    "    response_mode=\"compact\",\n",
    "    retriver_mode=\"hybrid\",\n",
    "    chat_mode=\"context\",\n",
    "    use_global_node_triplets=True,\n",
    "    max_keywords_per_query=10,\n",
    "    num_chunks_per_query=10,\n",
    "    similarity_top_k=3,\n",
    "    graph_store_query_depth=3,\n",
    "    include_text=False,\n",
    ")\n",
    "\n",
    "def chat_with_query(query):\n",
    "    response = chat_engine.chat(query)\n",
    "    eval_response = evaluator.evaluate_response(query, response)\n",
    "    return eval_response, query\n",
    "\n",
    "def print_chat_interface(response, query):\n",
    "    interface = f\"\"\"\n",
    "    QUERY: {query}\\n\n",
    "    --------------------------\\n\n",
    "    Context: {response.contexts}\\n\n",
    "    ---------------------------\\n\n",
    "    Response: {response.response}\n",
    "    \"\"\"\n",
    "    print(interface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "queries, responses = get_qr_pairs(num=70)\n",
    "indx = random.randint(a=0, b=70)\n",
    "query = queries[indx]\n",
    "reference = responses[indx]\n",
    "eval_response, query = chat_with_query(\"What is the average price for 1990 Chateau Petrus?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_chat_interface(eval_response, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness_eval = CorrectnessEvaluator(service_context=service_context)\n",
    "eval = correctness_eval.evaluate(query = query, response=eval_response.response, referece=reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_response, query = chat_with_query(\"What is the average price for 1990 Chateau Petrus?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_chat_interface(eval_response, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = kg_index.get_networkx_graph(limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(notebook = True, cdn_resources = \"remote\",\n",
    "                # bgcolor = \"#222222\",\n",
    "                font_color = \"black\",\n",
    "                height = \"750px\",\n",
    "                width = \"100%\",\n",
    "                select_menu = True,\n",
    "                filter_menu = True,\n",
    ")\n",
    "net.show_buttons(filter_=\"physics\")\n",
    "net.from_nx(G)\n",
    "net.show(\"nx.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G, seed=42, k=1.5)\n",
    "labels = nx.get_edge_attributes(G, 'label')\n",
    "plt.figure(figsize=(20, 20))\n",
    "nx.draw(G, pos, font_size=8, node_size=200, node_color='lightblue', edge_color='gray', alpha=0.6)\n",
    "# nx.draw_networkx_edge_labels(G, pos, font_size=3, label_pos=0.3, verticalalignment='baseline')\n",
    "plt.title('Knowledge Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in G.edges(data=True):\n",
    "    print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_dataset_path = Path(\"./app/data/evaluation/evaluation_evolved.json\")\n",
    "\n",
    "data_generator = DatasetGenerator.from_documents(\n",
    "    kg_pairings.sample(n=3000),\n",
    "    service_context=service_context,\n",
    "    question_gen_query=question_gen_query,\n",
    "    num_questions_per_chunk=2,\n",
    "    show_progress = True\n",
    ")\n",
    "eval_dataset = data_generator.generate_dataset_from_nodes(130)\n",
    "eval_dataset.save_json(eval_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine_parings-Y4sTaGQc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
