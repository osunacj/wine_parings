{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "from llama_index.core import Response\n",
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    DatasetGenerator,\n",
    "    BatchEvalRunner,\n",
    "    RelevancyEvaluator,\n",
    "    CorrectnessEvaluator,\n",
    ")\n",
    "\n",
    "from notebooks.helpers.bot.promtps import question_gen_query\n",
    "from evaluate_pairings import prepare_evalution_qa, parse_evalutions\n",
    "from app.notebooks.helpers.bot.kg_generation import create_kg_triplets\n",
    "from notebooks.helpers.bot.bot import (\n",
    "    get_chat_engine,\n",
    "    get_query_engine,\n",
    "    get_simple_query,\n",
    "    load_llm,\n",
    "    load_embedding_model,\n",
    "    setup_index_and_storage,\n",
    "    generate_pairings_documents,\n",
    "    service,\n",
    ")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_eval_df(query: str, response: Response, eval_result: Response) -> None:\n",
    "    eval_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Query\": query,\n",
    "            \"Response\": str(response),\n",
    "            \"Source\": (' '.join(eval_result.contexts)[:1000] + \"...\"),\n",
    "            \"Evaluation Result\": eval_result.passing,\n",
    "        },\n",
    "        index = [0]\n",
    "    )\n",
    "    eval_df = eval_df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"600px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        },\n",
    "        subset=[\"Response\", \"Source\"]\n",
    "    )\n",
    "    display(eval_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_triplets(text):\n",
    "    triplets = []\n",
    "    rows = text.split('\\n')\n",
    "    for row in rows[:-1]:\n",
    "        triplet = row.split('**')\n",
    "        triplets.append((triplet[0], triplet[1], triplet[2]))\n",
    "    return triplets\n",
    "\n",
    "kg_triplets = []\n",
    "\n",
    "KG = create_kg_triplets(sample_size=10, for_model=False)\n",
    "G = nx.DiGraph()\n",
    "for _, row in KG.iterrows():\n",
    "    triplets = parse_triplets(row['triplets'])\n",
    "    for triplet in triplets:\n",
    "        G.add_edge(triplet[0], triplet[2], label=triplet[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KG = create_kg_triplets(sample_size=601)\n",
    "kg_pairings = KG.apply(generate_pairings_documents, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: category=>Red\n",
      "variety_location=>Pinot Noir Victoria, Australia\n",
      "alcohol=>13.5%\n",
      "price=>$42\n",
      "variety=>Pinot Noir\n",
      "vintage=>2014\n",
      "winery=>Giant Steps\n",
      "country=>Australia\n",
      "province=>Victoria\n",
      "region=>Yarra Valley\n",
      "-----\n",
      "Content: The object wine, **Pinot Noir** has a relationship of **type_of** with the object **Red\n",
      "The object wine, **Pinot Noir** has a relationship of **variety_location** with the object **Pinot Noir Victoria, Australia\n",
      "The object wine, **Giant Steps 2014 Applejack Vineyard Pinot Noir (Yarra Valley)** has a relationship of **has_alcohol** with the object **13.5%\n",
      "The object wine, **Giant Steps 2014 Applejack Vineyard Pinot Noir (Yarra Valley)** has a relationship of **has_price_of** with the object **$42\n",
      "The object wine, **Giant Steps 2014 Applejack Vineyard Pinot Noir (Yarra Valley)** has a relationship of **has_variety** with the object **Pinot Noir\n",
      "The object wine, **Giant Steps 2014 Applejack Vineyard Pinot Noir (Yarra Valley)** has a relationship of **vintage_year_of** with the object **2014\n",
      "The object wine, **Giant Steps 2014 Applejack Vineyard Pinot Noir (Yarra Valley)** has a relationship of **produced_by_winery** with the object **Giant Steps\n",
      "The object wine, **Victoria** has a relationship of **in_country** with the object **Australia\n",
      "The object wine, **Yarra Valley** has a relationship of **in_province** with the object **Victoria\n",
      "The object wine, **Giant Steps** has a relationship of **from_province** with the object **Victoria\n",
      "The object wine, **Giant Steps** has a relationship of **from_region** with the object **Yarra Valley\n",
      "The object wine, **Giant Steps** has a relationship of **from_country** with the object **Australia\n",
      "The object wine, **Giant Steps** has a relationship of **produces_variety** with the object **Pinot Noir Victoria, Australia\n",
      "{'start': None, 'end': None}\n"
     ]
    }
   ],
   "source": [
    "print(kg_pairings.iloc[0].get_content(metadata_mode='llm'))\n",
    "print(kg_pairings.iloc[0].get_node_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = load_llm('openai3.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = load_embedding_model(\"openai3\")\n",
    "service_context = service(llm=llm, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "WARNING:llama_index.core.indices.knowledge_graph.base:Upgrading previously saved KG index to new storage format.\n",
      "Upgrading previously saved KG index to new storage format.\n"
     ]
    }
   ],
   "source": [
    "storage_context, kg_index = setup_index_and_storage(\n",
    "        service=service_context,\n",
    "        kg_pairings=kg_pairings,\n",
    "        show_progress=False,\n",
    "        max_triplets_chunk=10,\n",
    "        force=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = get_query_engine(\n",
    "    kg_index,\n",
    "    chat_mode=\"simple\",\n",
    "    retriver_mode=\"hybrid\",\n",
    "    response_mode=\"compact\",\n",
    "    use_global_node_triplets=True,\n",
    "    max_keywords_per_query=10,\n",
    "    num_chunks_per_query=10,\n",
    "    similarity_top_k=3,\n",
    "    graph_store_query_depth=3,\n",
    "    include_text = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = prepare_evalution_qa()\n",
    "eval_dataset = eval_dataset.sample(n=3, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevancy_eval = RelevancyEvaluator(service_context=service_context)\n",
    "faithfulness_eval = FaithfulnessEvaluator(service_context=service_context)\n",
    "correctness_eval = CorrectnessEvaluator(service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset[\"questions\"].to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BatchEvalRunner(\n",
    "    {\n",
    "        # \"faithfulness\": faithfulness_eval,\n",
    "        \"relevancy\": relevancy_eval,\n",
    "        },\n",
    "    workers=8,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "references = eval_dataset[\"responses\"].to_list()\n",
    "\n",
    "eval_results = runner.evaluate_queries(\n",
    "    query_engine,\n",
    "    queries=eval_dataset[\"questions\"].to_list(),\n",
    "    # eval_kwargs_lists={\n",
    "        # 'relevancy': {'', []},\n",
    "        # 'correctness': {'reference': references },\n",
    "    # },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset[\"responses\"].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_results.keys())\n",
    "print(eval_results[\"faithfulness\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_pairings import parse_evalutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_evalutions(\n",
    "    eval_results=eval_results,\n",
    "    model=\"gpt-3.5\",\n",
    "    embedding_model=\"gpt-3.5\",\n",
    "    response_mode=\"compact\",\n",
    "    retriever_mode=\"hybrid\",\n",
    "    chat_mode=\"simple\",  # Irrelevant if the response are from QueryEngine\n",
    "    evaluation_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_results[\"faithfulness\"][1].passing)\n",
    "print(eval_results[\"faithfulness\"][1].response)\n",
    "print(eval_results[\"faithfulness\"][1].contexts)\n",
    "print(eval_results[\"faithfulness\"][1].score)\n",
    "print(eval_results[\"faithfulness\"][1].pairwise_source)\n",
    "print(eval_results[\"faithfulness\"][1].invalid_result)\n",
    "print(eval_results[\"faithfulness\"][1].invalid_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = get_chat_engine(\n",
    "    kg_index,\n",
    "    chat_mode=\"context\",\n",
    "    retriver_mode=\"hybrid\",\n",
    "    use_global_node_triplets=True,\n",
    "    max_keywords_per_query=10,\n",
    "    num_chunks_per_query=10,\n",
    "    similarity_top_k=3,\n",
    "    graph_store_query_depth=3,\n",
    ")\n",
    "\n",
    "response = chat_engine.chat(\"What wine would you recommend pairing with a grilled steak?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_eval_df(question, response, eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = kg_index.get_networkx_graph(limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(notebook = True, cdn_resources = \"remote\",\n",
    "                # bgcolor = \"#222222\",\n",
    "                font_color = \"black\",\n",
    "                height = \"750px\",\n",
    "                width = \"100%\",\n",
    "                select_menu = True,\n",
    "                filter_menu = True,\n",
    ")\n",
    "net.show_buttons(filter_=\"physics\")\n",
    "net.from_nx(G)\n",
    "net.show(\"nx.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G, seed=42, k=1.5)\n",
    "labels = nx.get_edge_attributes(G, 'label')\n",
    "plt.figure(figsize=(20, 20))\n",
    "nx.draw(G, pos, font_size=8, node_size=200, node_color='lightblue', edge_color='gray', alpha=0.6)\n",
    "# nx.draw_networkx_edge_labels(G, pos, font_size=3, label_pos=0.3, verticalalignment='baseline')\n",
    "plt.title('Knowledge Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in G.edges(data=True):\n",
    "    print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine_parings-Y4sTaGQc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
